{"cells": [{"metadata": {"_cell_guid": "bfe16a81-e2b5-47b5-acef-8603e58e4a10", "_uuid": "1253fac77cf01574f233383d496bcd63d30497d2"}, "cell_type": "markdown", "source": ["# LSTAR Algorithm\n", "\n", "The L\\* algorithm has been introduced by Dana Angluin in 1987.  Its goal is to compute a Deterministic Finite States Automata (DFA) from a sequence of questions asked to a user about a goal langage."]}, {"source": ["# Our dependencies\n", "from graphviz import Digraph\n", "import numpy as np\n", "import pandas as pd\n", "import ipywidgets as widgets\n", "from ipywidgets import interactive\n", "from IPython.display import display\n", "import asyncio"], "metadata": {"collapsed": true, "_cell_guid": "378a0212-bcbd-4c9c-b783-befad867c84f", "_uuid": "95c380ceb9ddbb5a93d1d48668f9a4d7bae1aed9"}, "cell_type": "code", "outputs": [], "execution_count": 1}, {"metadata": {"_cell_guid": "da561993-1b85-4de4-8063-3201c00ba331", "_uuid": "9af5b114d05f91dba75d346e1f36c13222eee99b"}, "cell_type": "markdown", "source": ["This is for the widgets async handling, don't pay too much attention to it"]}, {"source": ["import asyncio\n", "from ipykernel.eventloops import register_integration\n", "\n", "@register_integration('asyncio')\n", "def loop_asyncio(kernel):\n", "    '''Start a kernel with asyncio event loop support.'''\n", "    loop = asyncio.get_event_loop()\n", "\n", "    def kernel_handler():\n", "        loop.call_soon(kernel.do_one_iteration)\n", "        loop.call_later(kernel._poll_interval, kernel_handler)\n", "\n", "    loop.call_soon(kernel_handler)\n", "    try:\n", "        if not loop.is_running():\n", "            loop.run_forever()\n", "    finally:\n", "        loop.run_until_complete(loop.shutdown_asyncgens())\n", "        loop.close()\n", "%gui asyncio"], "metadata": {"collapsed": true, "_cell_guid": "4d9b81c1-dcd5-4cd0-8155-4e959b7a412d", "_uuid": "3642ef6862dfd29315608ddc21024e63ce288695"}, "cell_type": "code", "outputs": [], "execution_count": 2}, {"source": ["#Some special chars\n", "lda = u\"\\u03BB\"\n", "cdot = u\"\\u00B7\""], "metadata": {"collapsed": true, "_cell_guid": "b1c73390-41da-4eab-9e1d-c6fe621be766", "_uuid": "d72e2c88b3feda4fc6ee242796b01bb84eb3d2a2"}, "cell_type": "code", "outputs": [], "execution_count": 3}, {"metadata": {"_cell_guid": "2a21fa2e-5fbe-4d54-9dd9-b911f44554a2", "_uuid": "f7955bdc0c3d0e304a182ae0de9246139298a23a"}, "cell_type": "markdown", "source": ["Let's define a class to run and render a DFA"]}, {"source": ["class DFA:\n", "    def __init__(self, alphabet, states_name, initial_state, final_states, transitions):\n", "        self.transitions = transitions.astype(int)\n", "        self.states_name = states_name\n", "        self.N = len(states_name)\n", "        self.alphabet = alphabet\n", "        self.rev_alphabet = {s: i for i, s in enumerate(self.alphabet)}\n", "        self.initial_state = initial_state\n", "        self.final_states = final_states\n", "        self.graph = self.make_dotgraph()\n", "        \n", "    def make_dotgraph(self):\n", "        graph = Digraph(comment='The Round Table', graph_attr={\"rankdir\": \"LR\"})\n", "        graph.attr('node', shape='circle')\n", "        graph.node(\".\", shape=\"point\")\n", "        \n", "        for i_s, s in enumerate(self.states_name):\n", "            graph.node(str(i_s), s, shape=\"doublecircle\" if i_s in self.final_states else None)\n", "        \n", "        graph.edge('.', str(self.initial_state))\n", "        \n", "        for i_state in range(self.N):\n", "            to_state = {}\n", "            for i_transition, transition in enumerate(self.alphabet):\n", "                i_next_state = self.transitions[i_state][i_transition]\n", "                to_state[i_next_state] = to_state.get(i_next_state, []) + [transition]\n", "            for i_next_state, transitions in to_state.items():\n", "                graph.edge(str(i_state), str(i_next_state), label=\",\".join(transitions))\n", "        \n", "        return graph\n", "    \n", "    def accept_word(self, word):\n", "        state = self.initial_state\n", "        for letter in word:\n", "            state = self.transitions[state][self.rev_alphabet[letter]]\n", "        return state in self.final_states"], "metadata": {"collapsed": true, "_cell_guid": "394b0487-593f-4fe1-ad2f-45605b8b4312", "_uuid": "ab3a4594b8d49274c8714f00b3f66016550ae878"}, "cell_type": "code", "outputs": [], "execution_count": 4}, {"metadata": {"_cell_guid": "de2b0728-cf12-4e3a-9912-05b3a3f19e36", "_uuid": "49b8bb2f57992704a5752259e98783900fc05e63"}, "cell_type": "markdown", "source": ["### Algorithm\n", "This is the LSTAR specific code"]}, {"source": ["class LSTAR:\n", "    SAS = \"S.A\\S\"\n", "    S = \"S\"\n", "        \n", "    def __init__(self, alphabet):\n", "        self.alphabet = alphabet\n", "        self.table = pd.DataFrame([[None, LSTAR.S]], index=[[lda], [lda]], columns=[\"result\", \"group\"])\n", "        self.table.index.set_names([\"word\", \"experiment\"], inplace=True)\n", "        self.table.sort_index(level=[\"word\", \"experiment\"], ascending=[1, 1], sort_remaining=True, inplace=True)\n", "        \n", "        self.all_results = {}\n", "        \n", "    def get_result(self, word, experiment):\n", "        # Defaults to None if word has not been calculated yet\n", "        return self.all_results.get(LSTAR.concat(word, experiment), None)\n", "    \n", "    def get_experiments(self):\n", "        return self.table.index.get_level_values(\"experiment\").unique()\n", "    \n", "    def concat(prefix, suffix):\n", "        res = (prefix + suffix).replace(lda, '')\n", "        return res if len(res) > 0 else lda\n", "        \n", "    def to_angluin_form(self):\n", "        return self.table.set_index(\"group\", append=True).unstack(level=\"experiment\").reorder_levels([1, 0]).sort_index()\n", "        \n", "    def compute_successors(self):\n", "        experiments = self.get_experiments()\n", "        \n", "        # Get the words of the first group of rows in the table\n", "        S_rows = self.table[self.table['group'] == LSTAR.S]\n", "        S_words = S_rows.index.get_level_values(\"word\").unique()\n", "        \n", "        # This is the S\u00b7A step\n", "        successors = set([LSTAR.concat(word, letter) for word in S_words for letter in self.alphabet])\n", "        \n", "        # We want to compute S\u00b7A\\S, so we have to remove S from S\u00b7A\n", "        successors = [succ for succ in successors if succ not in S_words]\n", "                \n", "        # errors='ignore' to not stop if we have not row in S\u00b7A\\S yet\n", "        new_table = self.table.drop(self.table[self.table['group'] == LSTAR.SAS].index, errors='ignore')\n", "        \n", "        for word in successors:\n", "            for experiment in experiments:\n", "                new_table.loc[(word, experiment), :] = [self.get_result(word, experiment), LSTAR.SAS]\n", "        \n", "        return new_table\n", "    \n", "    def get_holes(self):\n", "        # put the experiences in the index to get only one column, with either a value or a \"hole\"\n", "        missing_rows = self.table[self.table['result'].isnull()]\n", "        \n", "        # get the missing values as a list\n", "        holes = list(missing_rows.index.values)\n", "        \n", "        return holes\n", "    \n", "    async def get_and_fills_holes(self):\n", "        # get the table missing values\n", "        holes = self.get_holes()\n", "        \n", "        # ask the user to fill those missing values\n", "        concat_holes = [LSTAR.concat(word, experience) for word, experience in holes]\n", "        answers = await LSTAR.prompt_words(concat_holes)\n", "        holes_and_answers = list(zip(holes, answers))\n", "        \n", "        # put the user answers to the word+experience (concatenated) requests in our results list\n", "        # and fill the table with the answers\n", "        self.all_results.update(dict(zip(concat_holes, answers)))\n", "        \n", "        for (word, experience), answer in holes_and_answers:\n", "            self.table.loc[(word, experience), 'result'] = answer\n", "        \n", "\n", "    def make_concat_results(self):\n", "        # Let's get the distinct answers of the words in the potential states section \"S\"\n", "        # remember that each state is labelled by a word that gets to this state\n", "        # so here 'states' is actutally a list of words\n", "        concat_results = self.table.copy()\n", "        concat_column = self.table['result'].unstack(level=\"experiment\").apply(\n", "            lambda row: \"\".join(map(str, map(int, row))), axis=1\n", "        )\n", "        concat_results.index = concat_results.index.droplevel(level=\"experiment\")\n", "        concat_results = concat_results[~concat_results.index.duplicated(keep='first')]\n", "        concat_results['concat'] = concat_column\n", "        return concat_results\n", "            \n", "    def to_dfa(self):\n", "        concat_results = self.make_concat_results()\n", "        \n", "        df_states = concat_results[concat_results['group'] == LSTAR.S][['concat']].drop_duplicates()\n", "        states = df_states.index.get_level_values(\"word\").tolist()\n", "        \n", "        transitions = np.ndarray((len(states), len(self.alphabet)))\n", "        for i_state, state in enumerate(states):\n", "            for i_letter, letter in enumerate(self.alphabet):\n", "                \n", "                # get the concatenated results of the word after transition\n", "                # this will help us get the state corresponding to these kind\n", "                # of results\n", "                word_after_transition = LSTAR.concat(state, letter)\n", "                row_value = concat_results.loc[word_after_transition, 'concat']\n", "                                \n", "                next_state = df_states[(df_states['concat'] == row_value)].index.get_level_values(\"word\")[0]\n", "                \n", "                i_next_state = states.index(next_state)\n", "                transitions[i_state][i_letter] = i_next_state\n", "                \n", "        # get the first state, ie the one accessed by the empty word \n", "        i_initial_state = states.index(lda)\n", "        \n", "        # get the final states, ie the one whose experiment lambda (empty word) directly lead to an accepting state\n", "        true_lambda_result = self.table.query(\"experiment == '\"+lda+\"' and group == '\"+LSTAR.S+\"' and result == True\")\n", "        i_final_state_words = [states.index(word) for word in true_lambda_result.index.get_level_values(\"word\") if word in states]\n", "        \n", "        return DFA(self.alphabet, states, i_initial_state, i_final_state_words, transitions)\n", "    \n", "    \n", "    def close_table(self):\n", "        \n", "        # makes another column to held the full experiment results in a cell, easier to compare rows (=words)\n", "        concat_df = self.make_concat_results()\n", "        \n", "        # what is in the S group\n", "        results_in_s = concat_df[concat_df['group'] == 'S'][['concat']].drop_duplicates()\n", "        \n", "        # what is in S and SA (successors) ?\n", "        results_in_both = concat_df[['concat']].drop_duplicates()\n", "        \n", "        # what is in the successors and not in the potential states\n", "        \n", "        is_not_in_s = (pd.merge(results_in_s, results_in_both, how=\"outer\", indicator=True, left_index=True, right_index=True)['_merge'] == 'right_only')\n", "        df_misplaced = results_in_both[is_not_in_s.reindex(results_in_both.index)]\n", "        misplaced_words = df_misplaced.index.get_level_values('word').tolist()\n", "        \n", "        # for those words going outside of the potential states, we add them to the list possible state-words\n", "        # (ie states that are accessibles directly by executing the words that led to their creations)\n", "        for word in misplaced_words:\n", "            self.table.loc[word, 'group'] = LSTAR.S\n", "            \n", "        # return if there was no such misplace word, and so if the table was already closed\n", "        return len(misplaced_words) > 0\n", "    \n", "    def make_consistent_table(self):\n", "        experiments = self.get_experiments()\n", "        \n", "        concat_df = self.make_concat_results()\n", "        \n", "        df_S = concat_df[concat_df['group'] == LSTAR.S]\n", "                \n", "        for concat in df_S['concat'].unique():\n", "            same_state_words = df_S[df_S['concat'] == concat].index.values.tolist()\n", "            pairs = [(w1, w2) for i, w1 in enumerate(same_state_words) for w2 in same_state_words[i+1:]]\n", "\n", "            for w1, w2 in pairs:                \n", "                for letter in self.alphabet:\n", "                    next_w1 = LSTAR.concat(w1, letter)\n", "                    next_w2 = LSTAR.concat(w2, letter)\n", "                    \n", "                    # If there is an inconsistency, ie two words leading to the same state would either quit, \n", "                    # or stay in this state when concatenated with one more letter, although they should\n", "                    # respond the same way to the transition\n", "                    rows_equal = (self.table.loc[next_w1]['result'] == self.table.loc[next_w2]['result'])\n", "                    if not rows_equal.all():\n", "                        for inconsistent_experiment in (rows_equal[~rows_equal]).index.values:\n", "                            new_experiment = LSTAR.concat(letter, inconsistent_experiment)\n", "                            # print(\"Possible new experiment {}: {}\u00b7{}\".format(new_experiment, inconsistent_experiment, letter))\n", "                            \n", "                            # We dont add an experiment that is already in the list\n", "                            if new_experiment in experiments:\n", "                                print(\"New experiment {} already in the list\".format(new_experiment))\n", "                                continue\n", "                                \n", "                            # print(\"Inconsistency found: {} and {} go to different states through {}\u00b7{}\".format(w1, w2, inconsistent_experiment, letter))\n", "                            for word in self.table.index.get_level_values(\"word\"):\n", "                                self.table.loc[(word, new_experiment), :] = [self.get_result(word, new_experiment), self.table.loc[word].iloc[0]['group']]\n", "                            return True\n", "                \n", "        return False\n", "        \n", "    def add_word_to_test(self, word):\n", "        experiments = self.get_experiments()\n", "        prefixes = [word[:i+1] for i in range(len(word))]\n", "        for p in prefixes:\n", "            for experiment in experiments:\n", "                self.table.loc[(p, experiment), :] = [self.get_result(p, experiment), LSTAR.S]\n", "    \n", "    async def prompt_words(words):\n", "        # Here we define our interactive widgets\n", "        button_y = widgets.Button(description=\"Yes\")\n", "        button_y.on_click(lambda arg: click_answer.set_result(True))\n", "        button_n = widgets.Button(description=\"No\")\n", "        button_n.on_click(lambda arg: click_answer.set_result(False))\n", "        label = widgets.Label(\"\", layout=widgets.Layout(width='50%'))\n", "        layout = widgets.VBox([label, widgets.HBox([button_y, button_n])])\n", "        \n", "        # And display them\n", "        display(layout)\n", "        \n", "        results = []\n", "        \n", "        for word in words:\n", "            # Future that is going to be completed upon button click\n", "            click_answer = asyncio.Future()\n", "            label.value = \"Is '{}' in the langage ?\".format(word)\n", "            results.append(await click_answer)\n", "        \n", "        layout.close()\n", "        return results\n", "    \n", "    async def prompt_dfa(dfa):\n", "        answer = asyncio.Future()\n", "        \n", "        button_y = widgets.Button(description=\"This is the graph !\")\n", "        button_y.on_click(lambda arg: answer.set_result(True))\n", "        text = widgets.Text(description=\"Word\")\n", "        text.on_submit(lambda sender: answer.set_result(text.value))\n", "        label = widgets.Label(\"Is it this graph ? \\nIf not, enter a word that is not accepted and should, or is accepted and shouldn't\",\n", "                             layout=widgets.Layout(width='100%'))\n", "        \n", "        html_graph = widgets.HTML(dfa.graph._repr_svg_())\n", "        layout = widgets.VBox([label, html_graph, widgets.HBox([button_y, text])])\n", "        display(layout)\n", "        \n", "        res = await answer\n", "        \n", "        layout.close()\n", "        \n", "        return res\n", "    \n", "    async def _run(self):\n", "        self.table = self.compute_successors()\n", "        await self.get_and_fills_holes()\n", "        \n", "        \n", "        while True:\n", "\n", "            ready_for_equivalence_request = False\n", "            while not ready_for_equivalence_request:\n", "\n", "                was_not_closed = self.close_table()\n", "\n", "                # The conditions could be made shorter but a few more variables and lines\n", "                # are added for the sake for readability\n", "                to_fill = False\n", "\n", "                if was_not_closed:\n", "                    to_fill = True\n", "                else:\n", "                    was_not_consistent = self.make_consistent_table()\n", "\n", "                    if was_not_consistent:\n", "                            to_fill = True\n", "                if to_fill:\n", "                    self.table = self.compute_successors()\n", "                    await self.get_and_fills_holes()\n", "                else:\n", "                    ready_for_equivalence_request = True\n", "            \n", "            dfa = self.to_dfa()\n", "            answer = await LSTAR.prompt_dfa(dfa)\n", "            \n", "            if answer is True:\n", "                print(\"\ud83c\udf8a Yeay! \ud83c\udf8a\")\n", "                display(dfa.graph)\n", "                break\n", "            else:\n", "                self.add_word_to_test(answer)\n", "                self.table = self.compute_successors()\n", "                await self.get_and_fills_holes()\n", "    \n", "    def run(self):\n", "        asyncio.ensure_future(self._run())"], "metadata": {"collapsed": true, "_cell_guid": "66dc34f1-3969-491e-a403-c86f65ea23a1", "_uuid": "bed6a74ae8e0c26566f66a9cc1f9cb49feb6c793"}, "cell_type": "code", "outputs": [], "execution_count": 5}, {"source": ["model = LSTAR(alphabet=['a', 'b'])"], "metadata": {"collapsed": true, "_cell_guid": "d52816be-a1e3-4428-92a8-1d2abffaa412", "_uuid": "14e1074bd9b17bd0fd973bf19b0d007ed6b338a2"}, "cell_type": "code", "outputs": [], "execution_count": 6}, {"source": ["model.run()"], "metadata": {"_cell_guid": "2a2a2c31-c7b4-46df-9e98-daa6f9e2062e", "_uuid": "0529f680687255983925b7f60ca424c9107c03b6"}, "cell_type": "code", "outputs": [], "execution_count": 7}, {"source": [], "metadata": {"collapsed": true, "_cell_guid": "d2fdcdc1-72b5-481c-918d-8e0eca261cda", "_uuid": "725eb7233bdf9327f98321b636f26a11ee033b6b"}, "cell_type": "code", "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "version": "3.6.1", "name": "python"}}, "nbformat_minor": 1, "nbformat": 4}